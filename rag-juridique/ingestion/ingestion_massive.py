"""
Script d'ingestion MASSIVE de TOUTES les donn√©es juridiques

Strat√©gie :
- Un seul datastore Vertex AI
- Segmentation par m√©tadonn√©es (code_id, type, etat, etc.)
- Support multi-sources avec fallback
- Checkpointing pour reprendre en cas d'erreur
- Logs d√©taill√©s de progression

Usage:
    # Ing√©rer Code Civil complet
    python ingestion/ingestion_massive.py --code civil
    
    # Ing√©rer tous les codes
    python ingestion/ingestion_massive.py --all
    
    # Ing√©rer avec limite (test)
    python ingestion/ingestion_massive.py --all --max-articles 1000
"""

import argparse
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List
from tqdm import tqdm

from config.logging_config import get_logger
from config.settings import get_settings

logger = get_logger(__name__)
settings = get_settings()


class MassiveIngester:
    """Ingestion massive avec segmentation par m√©tadonn√©es"""
    
    # Mapping complet des codes juridiques fran√ßais
    CODES = {
        "civil": {
            "id": "LEGITEXT000006070721",
            "name": "Code civil",
            "articles_count": 8000,
            "priority": 1,  # Priorit√© d'ingestion
        },
        "penal": {
            "id": "LEGITEXT000006070716",
            "name": "Code p√©nal",
            "articles_count": 5000,
            "priority": 2,
        },
        "travail": {
            "id": "LEGITEXT000006072050",
            "name": "Code du travail",
            "articles_count": 10000,
            "priority": 3,
        },
        "commerce": {
            "id": "LEGITEXT000005634379",
            "name": "Code de commerce",
            "articles_count": 3000,
            "priority": 4,
        },
        "procedure_civile": {
            "id": "LEGITEXT000006070716",
            "name": "Code de proc√©dure civile",
            "articles_count": 2000,
            "priority": 5,
        },
        "procedure_penale": {
            "id": "LEGITEXT000006071164",
            "name": "Code de proc√©dure p√©nale",
            "articles_count": 2000,
            "priority": 6,
        },
        "securite_sociale": {
            "id": "LEGITEXT000006073189",
            "name": "Code de la s√©curit√© sociale",
            "articles_count": 5000,
            "priority": 7,
        },
    }
    
    def __init__(
        self,
        code_name: Optional[str] = None,
        max_articles: Optional[int] = None,
        checkpoint_dir: Path = Path("data/checkpoints"),
    ):
        """
        Initialise l'ingestion massive
        
        Args:
            code_name: Nom du code √† ing√©rer (None = tous)
            max_articles: Nombre maximum d'articles par code (None = tous)
            checkpoint_dir: Dossier pour les checkpoints
        """
        self.code_name = code_name
        self.max_articles = max_articles
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # Statistiques
        self.stats = {
            "total_articles": 0,
            "codes_processed": 0,
            "errors": 0,
            "start_time": datetime.now(),
        }
        
        logger.info("=" * 70)
        logger.info("üöÄ INGESTION MASSIVE - Donn√©es Juridiques")
        logger.info("=" * 70)
        logger.info(f"   Code(s): {code_name or 'TOUS'}")
        logger.info(f"   Max articles/code: {max_articles or 'illimit√©'}")
        logger.info(f"   Checkpoint dir: {checkpoint_dir}")
    
    def run(self) -> bool:
        """Lance l'ingestion massive"""
        try:
            if self.code_name:
                # Ing√©rer un seul code
                if self.code_name not in self.CODES:
                    logger.error(f"‚ùå Code inconnu: {self.code_name}")
                    return False
                
                code_info = self.CODES[self.code_name]
                return self._ingest_code(self.code_name, code_info)
            else:
                # Ing√©rer tous les codes par ordre de priorit√©
                codes_sorted = sorted(
                    self.CODES.items(),
                    key=lambda x: x[1]["priority"]
                )
                
                logger.info(f"\nüìö Ingestion de {len(codes_sorted)} codes juridiques")
                
                for code_name, code_info in codes_sorted:
                    logger.info(f"\n{'='*70}")
                    logger.info(f"üìñ Code: {code_info['name']} (priorit√© {code_info['priority']})")
                    logger.info(f"{'='*70}")
                    
                    success = self._ingest_code(code_name, code_info)
                    if not success:
                        logger.warning(f"‚ö†Ô∏è √âchec pour {code_info['name']}, continuation...")
                        self.stats["errors"] += 1
                    
                    self.stats["codes_processed"] += 1
                    
                    # Pause entre codes pour √©viter surcharge
                    time.sleep(2)
                
                return self._finalize()
        
        except KeyboardInterrupt:
            logger.warning("\n‚ö†Ô∏è Interruption utilisateur")
            self._save_checkpoint()
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur critique: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def _ingest_code(self, code_name: str, code_info: Dict[str, Any]) -> bool:
        """Ing√®re un code sp√©cifique"""
        logger.info(f"üìö Ingestion: {code_info['name']}")
        
        # V√©rifier checkpoint
        checkpoint_file = self.checkpoint_dir / f"{code_name}_checkpoint.json"
        start_from = 0
        
        if checkpoint_file.exists():
            logger.info(f"   üìç Checkpoint trouv√©: {checkpoint_file}")
            try:
                with open(checkpoint_file, "r", encoding="utf-8") as f:
                    checkpoint = json.load(f)
                    start_from = checkpoint.get("last_article_index", 0)
                    logger.info(f"   ‚ñ∂Ô∏è Reprise depuis l'article {start_from}")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è Erreur lecture checkpoint: {e}")
        
        # Strat√©gie d'ingestion avec fallback
        strategies = [
            ("Hugging Face", self._try_huggingface),
            ("data.gouv.fr", self._try_datagouv),
            ("Fichiers locaux", self._try_local_files),
            ("G√©n√©ration enrichie", self._try_generate_enriched),
        ]
        
        for strategy_name, strategy_func in strategies:
            logger.info(f"\nüì• Strat√©gie: {strategy_name}...")
            try:
                articles = strategy_func(code_name, code_info, start_from)
                
                if articles and len(articles) > 0:
                    # Sauvegarder checkpoint
                    self._save_checkpoint_code(code_name, len(articles))
                    
                    # Exporter
                    output_path = self._export_articles(code_name, code_info, articles)
                    
                    logger.success(f"‚úÖ {len(articles)} articles ing√©r√©s")
                    logger.info(f"   üìÅ Fichier: {output_path}")
                    
                    self.stats["total_articles"] += len(articles)
                    
                    return True
            
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è √âchec {strategy_name}: {e}")
                continue
        
        logger.error(f"‚ùå Toutes les strat√©gies ont √©chou√© pour {code_info['name']}")
        return False
    
    def _try_huggingface(
        self,
        code_name: str,
        code_info: Dict[str, Any],
        start_from: int = 0,
    ) -> List[Dict[str, Any]]:
        """Essaie de charger depuis Hugging Face"""
        try:
            from datasets import load_dataset
            
            # Datasets √† essayer
            datasets = [
                "antoinejeannot/code-civil-fr",
                "antoinejeannot/french-jurisprudence",
            ]
            
            for dataset_name in datasets:
                try:
                    logger.info(f"   üîç Tentative: {dataset_name}")
                    dataset = load_dataset(dataset_name, split="train", streaming=True)
                    
                    articles = []
                    max_count = self.max_articles or code_info["articles_count"]
                    
                    for i, item in enumerate(dataset):
                        if i < start_from:
                            continue
                        
                        if self.max_articles and len(articles) >= self.max_articles:
                            break
                        
                        content = item.get("text", "") or item.get("content", "")
                        if not content:
                            continue
                        
                        article = self._create_article(
                            code_info=code_info,
                            article_id=f"{code_info['id']}_HF_{i:06d}",
                            num=str(i + 1),
                            content=content[:10000],  # Limiter taille
                            source="Hugging Face",
                        )
                        articles.append(article)
                    
                    if articles:
                        logger.success(f"   ‚úÖ {len(articles)} articles depuis Hugging Face")
                        return articles
                
                except Exception as e:
                    logger.debug(f"   Erreur {dataset_name}: {e}")
                    continue
            
            return []
        
        except ImportError:
            logger.warning("   ‚ö†Ô∏è 'datasets' non install√© (pip install datasets)")
            return []
    
    def _try_datagouv(
        self,
        code_name: str,
        code_info: Dict[str, Any],
        start_from: int = 0,
    ) -> List[Dict[str, Any]]:
        """Essaie de t√©l√©charger depuis DILA/data.gouv.fr"""
        # Essayer DILA d'abord
        logger.info("   üîç Tentative DILA OPENDATA...")
        
        try:
            from ingestion.sources.dila_opendata import DILAOpendataClient
            
            client = DILAOpendataClient()
            
            # Calculer max_articles si n√©cessaire
            max_articles = None
            if self.max_articles:
                # Ajuster selon start_from
                max_articles = self.max_articles + start_from
            
            # Ing√©rer depuis DILA
            articles_raw = client.ingest_code(
                code_id=code_info["id"],
                max_articles=max_articles,
            )
            
            if articles_raw:
                # Appliquer start_from
                if start_from > 0:
                    articles_raw = articles_raw[start_from:]
                
                # Limiter si max_articles
                if self.max_articles and len(articles_raw) > self.max_articles:
                    articles_raw = articles_raw[:self.max_articles]
                
                # Convertir au format Vertex AI
                articles = []
                for art in articles_raw:
                    article = self._create_article(
                        code_info=code_info,
                        article_id=art["id"],
                        num=art["num"],
                        content=art["content"],
                        breadcrumb=art.get("breadcrumb", ""),
                        date_debut=art.get("date_debut", "1804-02-07"),
                        date_fin=art.get("date_fin"),
                        etat=art.get("etat", "VIGUEUR"),
                        source="DILA OPENDATA",
                    )
                    articles.append(article)
                
                if articles:
                    logger.success(f"   ‚úÖ {len(articles)} articles depuis DILA")
                    return articles
        except Exception as e:
            logger.debug(f"   DILA √©chou√©: {e}")
        
        # Si DILA √©choue, essayer data.gouv.fr
        logger.info("   üîç Tentative data.gouv.fr...")
        
        try:
            from ingestion.sources.datagouv_client import DataGouvClient
            
            client = DataGouvClient()
            
            # T√©l√©charger les ressources
            resources = client.list_resources()
            
            if not resources:
                logger.warning("   ‚ö†Ô∏è Aucune ressource trouv√©e sur data.gouv.fr")
                return []
            
            # Pour l'instant, on t√©l√©charge juste pour voir ce qu'il y a
            # Le parsing d√©pendra du format des fichiers
            logger.info("   ‚ÑπÔ∏è Ressources disponibles sur data.gouv.fr")
            logger.info("   ‚ÑπÔ∏è T√©l√©chargez manuellement depuis la page web")
            logger.info("   ‚ÑπÔ∏è Mettez les fichiers dans data/raw/datagouv/")
            logger.info("   ‚ÑπÔ∏è Le script les utilisera automatiquement")
            
            # V√©rifier si on a d√©j√† des fichiers locaux
            datagouv_dir = Path("data/raw/datagouv")
            if datagouv_dir.exists():
                files = list(datagouv_dir.glob("*.xml"))
                if files:
                    logger.info(f"   üìÅ {len(files)} fichiers XML trouv√©s localement")
                    logger.warning("   ‚ö†Ô∏è Parsing data.gouv.fr XML non encore impl√©ment√©")
                    # TODO: Impl√©menter le parsing selon le format r√©el
        
        except Exception as e:
            logger.debug(f"   data.gouv.fr √©chou√©: {e}")
        
        return []
    
    def _try_local_files(
        self,
        code_name: str,
        code_info: Dict[str, Any],
        start_from: int = 0,
    ) -> List[Dict[str, Any]]:
        """Essaie de charger depuis fichiers locaux (DILA extraits)"""
        # Chercher dans data/raw/dila/{code_id}/
        dila_dir = Path("data") / "raw" / "dila" / code_info["id"]
        
        if not dila_dir.exists():
            logger.debug("   Aucun dossier DILA local trouv√©")
            return []
        
        logger.info("   üìÅ Fichiers locaux DILA trouv√©s, parsing...")
        
        try:
            from ingestion.sources.dila_opendata import DILAOpendataClient
            
            client = DILAOpendataClient()
            
            # Trouver les fichiers XML
            xml_files = client.find_xml_files(dila_dir)
            
            if not xml_files:
                logger.warning("   ‚ö†Ô∏è Aucun fichier XML trouv√© dans le dossier local")
                return []
            
            # Parser tous les fichiers
            all_articles = []
            
            for xml_file in xml_files:
                articles = client.parse_legi_xml(xml_file)
                all_articles.extend(articles)
                
                if self.max_articles and len(all_articles) >= self.max_articles:
                    all_articles = all_articles[:self.max_articles]
                    break
            
            # Appliquer start_from
            if start_from > 0:
                all_articles = all_articles[start_from:]
            
            if not all_articles:
                return []
            
            # Convertir au format Vertex AI
            articles = []
            for art in all_articles:
                article = self._create_article(
                    code_info=code_info,
                    article_id=art["id"],
                    num=art["num"],
                    content=art["content"],
                    breadcrumb=art.get("breadcrumb", ""),
                    date_debut=art.get("date_debut", "1804-02-07"),
                    date_fin=art.get("date_fin"),
                    etat=art.get("etat", "VIGUEUR"),
                    source="DILA OPENDATA (local)",
                )
                articles.append(article)
            
            if articles:
                logger.success(f"   ‚úÖ {len(articles)} articles depuis fichiers locaux")
                return articles
            else:
                return []
        
        except ImportError as e:
            logger.warning(f"   ‚ö†Ô∏è D√©pendances manquantes: {e}")
            return []
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Erreur parsing fichiers locaux: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def _try_generate_enriched(
        self,
        code_name: str,
        code_info: Dict[str, Any],
        start_from: int = 0,
    ) -> List[Dict[str, Any]]:
        """G√©n√®re un dataset enrichi (fallback)"""
        logger.info("   üé® G√©n√©ration enrichie...")
        
        # Utiliser le script existant pour Code Civil
        if code_name == "civil":
            from ingestion.ingestion_datagouv_simple import SimpleCodeCivilIngester
            ingester = SimpleCodeCivilIngester()
            # La m√©thode _generate_enriched_dataset retourne True mais ne retourne pas les articles
            # On va cr√©er les articles directement ici
            return self._get_essential_articles_civil(code_info)
        else:
            logger.warning(f"   ‚ö†Ô∏è Articles essentiels non d√©finis pour {code_info['name']}")
            return []
    
    def _get_essential_articles_civil(self, code_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """R√©cup√®re les articles essentiels du Code Civil (21 articles)"""
        # Liste compl√®te des articles essentiels du Code Civil
        essential_articles = [
            {
                "num": "1",
                "content": "Les lois et, lorsqu'ils sont publi√©s au Journal officiel de la R√©publique fran√ßaise, les actes administratifs entrent en vigueur √† la date qu'ils fixent ou, √† d√©faut, le lendemain de leur publication. Toutefois, l'entr√©e en vigueur de celles de leurs dispositions dont l'ex√©cution n√©cessite des mesures d'application est report√©e √† la date d'entr√©e en vigueur de ces mesures.",
                "breadcrumb": "Code civil > Livre pr√©liminaire > Titre Ier > Article 1",
                "date_debut": "1804-02-07",
            },
            {
                "num": "2",
                "content": "La loi ne dispose que pour l'avenir ; elle n'a point d'effet r√©troactif.",
                "breadcrumb": "Code civil > Livre pr√©liminaire > Titre Ier > Article 2",
                "date_debut": "1804-02-07",
            },
            {
                "num": "3",
                "content": "Les lois de police et de s√ªret√© obligent tous ceux qui habitent le territoire. Les immeubles, m√™me ceux poss√©d√©s par des √©trangers, sont r√©gis par la loi fran√ßaise. Les lois concernant l'√©tat et la capacit√© des personnes r√©gissent les Fran√ßais, m√™me r√©sidant en pays √©tranger.",
                "breadcrumb": "Code civil > Livre pr√©liminaire > Titre Ier > Article 3",
                "date_debut": "1804-02-07",
            },
            {
                "num": "4",
                "content": "Le juge qui refusera de juger, sous pr√©texte du silence, de l'obscurit√© ou de l'insuffisance de la loi, pourra √™tre poursuivi comme coupable de d√©ni de justice.",
                "breadcrumb": "Code civil > Livre pr√©liminaire > Titre Ier > Article 4",
                "date_debut": "1804-02-07",
            },
            {
                "num": "5",
                "content": "Il est d√©fendu aux juges de prononcer par voie de disposition g√©n√©rale et r√©glementaire sur les causes qui leur sont soumises.",
                "breadcrumb": "Code civil > Livre pr√©liminaire > Titre Ier > Article 5",
                "date_debut": "1804-02-07",
            },
            {
                "num": "414",
                "content": "La majorit√© est fix√©e √† dix-huit ans accomplis ; √† cet √¢ge, chacun est capable d'exercer les droits dont il a la jouissance.",
                "breadcrumb": "Code civil > Livre I > Titre XI > Chapitre Ier > Section 1 > Article 414",
                "date_debut": "2009-01-01",
            },
            {
                "num": "515",
                "content": "Les enfants dont la filiation est l√©galement √©tablie ont les m√™mes droits et les m√™mes devoirs dans leurs rapports avec leur p√®re et m√®re. Ils entrent dans la famille de chacun d'eux.",
                "breadcrumb": "Code civil > Livre I > Titre VII > Article 515",
                "date_debut": "2005-07-01",
            },
            {
                "num": "1101",
                "content": "Le contrat est un accord de volont√©s entre deux ou plusieurs personnes destin√© √† cr√©er, modifier, transmettre ou √©teindre des obligations.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre I > Section 1 > Article 1101",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1102",
                "content": "Chacun est libre de contracter ou de ne pas contracter, de choisir son cocontractant et de d√©terminer le contenu et la forme du contrat dans les limites fix√©es par la loi. La libert√© contractuelle ne permet pas de d√©roger aux r√®gles qui int√©ressent l'ordre public.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre I > Section 1 > Article 1102",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1103",
                "content": "Les contrats l√©galement form√©s tiennent lieu de loi √† ceux qui les ont faits.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre I > Section 1 > Article 1103",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1104",
                "content": "Les contrats doivent √™tre n√©goci√©s, form√©s et ex√©cut√©s de bonne foi. Cette disposition est d'ordre public.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre I > Section 1 > Article 1104",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1105",
                "content": "Les contrats, qu'ils aient ou non une d√©nomination propre, sont soumis √† des r√®gles g√©n√©rales, qui sont l'objet du pr√©sent sous-titre. Les r√®gles particuli√®res √† certains contrats sont √©tablies dans les dispositions propres √† chacun d'eux. Les r√®gles g√©n√©rales s'appliquent sous r√©serve de ces r√®gles particuli√®res.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre I > Section 1 > Article 1105",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1128",
                "content": "Sont n√©cessaires √† la validit√© d'un contrat : 1¬∞ Le consentement des parties ; 2¬∞ Leur capacit√© de contracter ; 3¬∞ Un contenu licite et certain.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre II > Section 1 > Article 1128",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1231-1",
                "content": "Le d√©biteur est condamn√©, s'il y a lieu, au paiement de dommages et int√©r√™ts soit √† raison de l'inex√©cution de l'obligation, soit √† raison du retard dans l'ex√©cution, s'il ne justifie pas que l'ex√©cution a √©t√© emp√™ch√©e par la force majeure.",
                "breadcrumb": "Code civil > Livre III > Titre III > Chapitre IV > Section 1 > Article 1231-1",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1240",
                "content": "Tout fait quelconque de l'homme, qui cause √† autrui un dommage, oblige celui par la faute duquel il est arriv√© √† le r√©parer.",
                "breadcrumb": "Code civil > Livre III > Titre IV > Chapitre II > Article 1240",
                "date_debut": "2016-10-01",
            },
            {
                "num": "1583",
                "content": "La vente est parfaite entre les parties, et la propri√©t√© est acquise de droit √† l'acheteur √† l'√©gard du vendeur, d√®s qu'on est convenu de la chose et du prix, quoique la chose n'ait pas encore √©t√© livr√©e ni le prix pay√©.",
                "breadcrumb": "Code civil > Livre III > Titre VI > Chapitre Ier > Article 1583",
                "date_debut": "1804-02-07",
            },
            {
                "num": "1604",
                "content": "La d√©livrance est le transport de la chose vendue en la puissance et possession de l'acheteur.",
                "breadcrumb": "Code civil > Livre III > Titre VI > Chapitre III > Article 1604",
                "date_debut": "1804-02-07",
            },
            {
                "num": "1641",
                "content": "Le vendeur est tenu de la garantie √† raison des d√©fauts cach√©s de la chose vendue qui la rendent impropre √† l'usage auquel on la destine, ou qui diminuent tellement cet usage que l'acheteur ne l'aurait pas acquise, ou n'en aurait donn√© qu'un moindre prix, s'il les avait connus.",
                "breadcrumb": "Code civil > Livre III > Titre VI > Chapitre V > Section 4 > Article 1641",
                "date_debut": "1804-02-07",
            },
            {
                "num": "1709",
                "content": "Le louage des choses est un contrat par lequel l'une des parties s'oblige √† faire jouir l'autre d'une chose pendant un certain temps, et moyennant un certain prix que celle-ci s'oblige de lui payer.",
                "breadcrumb": "Code civil > Livre III > Titre VIII > Chapitre I > Article 1709",
                "date_debut": "1804-02-07",
            },
            {
                "num": "544",
                "content": "La propri√©t√© est le droit de jouir et disposer des choses de la mani√®re la plus absolue, pourvu qu'on n'en fasse pas un usage prohib√© par les lois ou par les r√®glements.",
                "breadcrumb": "Code civil > Livre II > Titre Ier > Chapitre II > Article 544",
                "date_debut": "1804-02-07",
            },
        ]
        
        # Limiter si max_articles sp√©cifi√©
        if self.max_articles and len(essential_articles) > self.max_articles:
            essential_articles = essential_articles[:self.max_articles]
            logger.info(f"   ‚ö†Ô∏è Limit√© √† {self.max_articles} articles (max sp√©cifi√©)")
        
        articles = []
        for idx, art in enumerate(essential_articles):
            article = self._create_article(
                code_info=code_info,
                article_id=f"{code_info['id']}_ENRICHED_{idx:06d}",
                num=art["num"],
                content=art["content"],
                breadcrumb=art.get("breadcrumb", f"Code civil > Article {art['num']}"),
                date_debut=art.get("date_debut", "1804-02-07"),
                date_fin=art.get("date_fin"),
                etat=art.get("etat", "VIGUEUR"),
                source="Dataset enrichi",
            )
            articles.append(article)
        
        logger.info(f"   ‚úÖ {len(articles)} articles essentiels g√©n√©r√©s")
        return articles
    
    def _create_article(
        self,
        code_info: Dict[str, Any],
        article_id: str,
        num: str,
        content: str,
        breadcrumb: str = "",
        date_debut: str = "1804-02-07",
        date_fin: Optional[str] = None,
        etat: str = "VIGUEUR",
        source: str = "Ingestion",
    ) -> Dict[str, Any]:
        """
        Cr√©e un article au format Vertex AI avec m√©tadonn√©es compl√®tes
        
        NOUVEAU FORMAT : Champs directs pour activer embeddings et segmentation automatique
        - content: Champ direct (pour embeddings)
        - title: Champ direct (pour affichage)
        - M√©tadonn√©es: Champs directs (pour filtrage)
        
        M√©tadonn√©es pour segmentation :
        - code_id: ID du code (filtrage par code)
        - code_name: Nom du code (affichage)
        - type: Type de document (article_code, jurisprudence, etc.)
        - etat: √âtat (VIGUEUR, ABROGE, MODIFIE)
        - date_debut/date_fin: Dates (filtrage temporel)
        - article_num: Num√©ro d'article (recherche pr√©cise)
        """
        if not breadcrumb:
            breadcrumb = f"{code_info['name']} > Article {num}"
        
        # NOUVEAU FORMAT : Champs directs (pas dans jsonData)
        # Cela permet √† Vertex AI de cr√©er des embeddings sur le champ 'content'
        # et d'activer la segmentation automatique
        return {
            "id": article_id,
            # Champ direct pour embeddings et segmentation
            "content": content,
            "title": f"Article {num}",
            
            # M√©tadonn√©es en champs directs pour filtrage
            "code_id": code_info["id"],
            "code_name": code_info["name"],
            "type": "article_code",
            "nature": "CODE",
            "article_id": article_id,
            "article_num": num,
            "breadcrumb": breadcrumb,
            "etat": etat,
            "date_debut": date_debut,
            "date_fin": date_fin or "",
            "source": source,
            "ingestion_date": datetime.now().isoformat(),
        }
    
    def _export_articles(
        self,
        code_name: str,
        code_info: Dict[str, Any],
        articles: List[Dict[str, Any]],
    ) -> Path:
        """Exporte les articles en JSONL"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = settings.EXPORT_DIR / f"{code_info['id']}_{code_name}_{timestamp}.jsonl"
        
        with open(output_path, "w", encoding="utf-8") as f:
            for article in articles:
                f.write(json.dumps(article, ensure_ascii=False) + "\n")
        
        logger.info(f"   üíæ Export: {output_path}")
        logger.info(f"   üìä {len(articles)} articles, {output_path.stat().st_size / 1024:.1f} KB")
        
        return output_path
    
    def _save_checkpoint_code(self, code_name: str, articles_count: int) -> None:
        """Sauvegarde un checkpoint pour un code"""
        checkpoint_file = self.checkpoint_dir / f"{code_name}_checkpoint.json"
        
        checkpoint = {
            "code_name": code_name,
            "last_article_index": articles_count,
            "timestamp": datetime.now().isoformat(),
        }
        
        with open(checkpoint_file, "w", encoding="utf-8") as f:
            json.dump(checkpoint, f, indent=2)
    
    def _save_checkpoint(self) -> None:
        """Sauvegarde un checkpoint global"""
        checkpoint_file = self.checkpoint_dir / "global_checkpoint.json"
        
        checkpoint = {
            "stats": self.stats,
            "timestamp": datetime.now().isoformat(),
        }
        
        with open(checkpoint_file, "w", encoding="utf-8") as f:
            json.dump(checkpoint, f, indent=2)
        
        logger.info(f"üíæ Checkpoint sauvegard√©: {checkpoint_file}")
    
    def _finalize(self) -> bool:
        """Finalise l'ingestion et affiche les statistiques"""
        duration = (datetime.now() - self.stats["start_time"]).total_seconds()
        
        logger.info("\n" + "=" * 70)
        logger.info("‚úÖ INGESTION MASSIVE TERMIN√âE")
        logger.info("=" * 70)
        logger.info(f"üìä Statistiques:")
        logger.info(f"   - Codes trait√©s: {self.stats['codes_processed']}")
        logger.info(f"   - Articles totaux: {self.stats['total_articles']}")
        logger.info(f"   - Erreurs: {self.stats['errors']}")
        logger.info(f"   - Dur√©e: {duration:.1f} secondes")
        logger.info("=" * 70)
        
        logger.info("\nüì§ PROCHAINES √âTAPES:")
        logger.info("1. Uploader les fichiers JSONL vers Cloud Storage:")
        logger.info(f"   gsutil -m cp {settings.EXPORT_DIR}/*.jsonl gs://legal-rag-data-sofia-2025/")
        logger.info("\n2. Importer dans Vertex AI Search:")
        logger.info("   GCP Console > Vertex AI Search > datastorerag_1766055384992")
        logger.info("   > Importer > S√©lectionner les fichiers depuis GCS")
        logger.info("\n3. V√©rifier la segmentation par m√©tadonn√©es:")
        logger.info("   - Filtres par code_id fonctionnels")
        logger.info("   - Filtres par etat fonctionnels")
        logger.info("   - Recherche s√©mantique op√©rationnelle")
        
        return True


def main():
    """Point d'entr√©e"""
    parser = argparse.ArgumentParser(
        description="Ingestion massive de donn√©es juridiques",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--code",
        choices=list(MassiveIngester.CODES.keys()),
        default=None,
        help="Code juridique √† ing√©rer (d√©faut: tous)"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Ing√©rer tous les codes"
    )
    parser.add_argument(
        "--max-articles",
        type=int,
        default=None,
        help="Nombre maximum d'articles par code (d√©faut: illimit√©)"
    )
    parser.add_argument(
        "--checkpoint-dir",
        type=Path,
        default=Path("data/checkpoints"),
        help="Dossier pour les checkpoints"
    )
    
    args = parser.parse_args()
    
    if args.all:
        code_name = None
    elif args.code:
        code_name = args.code
    else:
        # Par d√©faut, ing√©rer tous les codes
        code_name = None
        logger.info("‚ÑπÔ∏è Aucun code sp√©cifi√©, ingestion de tous les codes")
    
    ingester = MassiveIngester(
        code_name=code_name,
        max_articles=args.max_articles,
        checkpoint_dir=args.checkpoint_dir,
    )
    
    success = ingester.run()
    
    if success:
        logger.success("\n‚úÖ Ingestion termin√©e avec succ√®s!")
        return 0
    else:
        logger.error("\n‚ùå Ingestion termin√©e avec des erreurs")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())

