"""
Script pour t√©l√©charger, extraire et ing√©rer l'archive Freemium LEGI

Usage:
    python ingestion/download_and_ingest_freemium.py
"""

import tarfile
from pathlib import Path
from typing import Optional

from config.logging_config import get_logger
from ingestion.sources.datagouv_client import DataGouvClient
from ingestion.sources.dila_opendata import DILAOpendataClient

logger = get_logger(__name__)


def download_freemium() -> Optional[Path]:
    """T√©l√©charge l'archive Freemium"""
    logger.info("=" * 70)
    logger.info("üì• T√âL√âCHARGEMENT ARCHIVE FREEMIUM LEGI")
    logger.info("=" * 70)
    
    client = DataGouvClient()
    archive_path = client.download_freemium_archive()
    
    if archive_path:
        logger.success(f"‚úÖ Archive t√©l√©charg√©e: {archive_path}")
        return archive_path
    else:
        logger.error("‚ùå √âchec du t√©l√©chargement")
        return None


def extract_archive(archive_path: Path, extract_dir: Optional[Path] = None) -> Optional[Path]:
    """Extrait l'archive tar.gz"""
    logger.info("=" * 70)
    logger.info("üì¶ EXTRACTION ARCHIVE")
    logger.info("=" * 70)
    
    if extract_dir is None:
        # Utiliser un chemin court pour √©viter probl√®me Windows
        extract_dir = Path("C:/LEGI") if Path("C:/").exists() else archive_path.parent / "LEGI_extracted"
    
    extract_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"üìÇ Extraction vers: {extract_dir}")
    
    try:
        # V√©rifier si d√©j√† extrait
        if extract_dir.exists() and any(extract_dir.iterdir()):
            logger.info("   ‚úÖ Archive d√©j√† extraite")
            return extract_dir
        
        logger.info("   üì¶ Extraction en cours...")
        logger.warning("   ‚ö†Ô∏è Sur Windows, l'extraction peut √™tre lente √† cause des chemins longs")
        logger.info("   üí° Alternative: Utiliser 7-Zip pour extraire manuellement")
        
        # Essayer avec tarfile mais avec gestion d'erreurs
        import os
        import sys
        
        try:
            with tarfile.open(archive_path, "r:gz") as tar:
                # Compter les membres
                members = tar.getmembers()
                logger.info(f"   üìÑ {len(members)} fichiers √† extraire")
                
                # Extraire avec filter='data' pour √©viter les probl√®mes de s√©curit√©
                tar.extractall(extract_dir, filter='data')
                
                logger.success(f"   ‚úÖ Archive extraite: {extract_dir}")
                return extract_dir
        
        except Exception as e:
            logger.error(f"   ‚ùå Erreur extraction avec tarfile: {e}")
            logger.info("   üí° Solution: Extraire manuellement avec 7-Zip")
            logger.info(f"   üìÅ Archive: {archive_path}")
            logger.info(f"   üìÅ Destination: {extract_dir}")
            logger.info("   Commandes 7-Zip:")
            logger.info(f"   7z x \"{archive_path}\" -o\"{extract_dir}\"")
            return None
    
    except Exception as e:
        logger.error(f"   ‚ùå Erreur extraction: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def ingest_from_extracted(extract_dir: Path, code_ids: Optional[list] = None) -> int:
    """
    Ing√®re les codes depuis l'archive extraite
    
    Args:
        extract_dir: Dossier extrait
        code_ids: Liste des code_ids √† ing√©rer (None = tous)
    
    Returns:
        Nombre d'articles ing√©r√©s
    """
    logger.info("=" * 70)
    logger.info("üìö INGESTION DES CODES")
    logger.info("=" * 70)
    
    # Mapping code_id ‚Üí nom
    CODE_MAPPING = {
        "LEGITEXT000006070721": "Code civil",
        "LEGITEXT000006070716": "Code p√©nal",
        "LEGITEXT000006072050": "Code du travail",
        "LEGITEXT000005634379": "Code de commerce",
        "LEGITEXT000006071164": "Code de proc√©dure civile",
        "LEGITEXT000006071165": "Code de proc√©dure p√©nale",
        "LEGITEXT000006073189": "Code de la s√©curit√© sociale",
    }
    
    client = DILAOpendataClient()
    
    # Chercher les dossiers de codes
    legi_dir = extract_dir / "LEGI"
    if not legi_dir.exists():
        # Essayer structure alternative
        legi_dir = extract_dir
        for subdir in extract_dir.iterdir():
            if subdir.is_dir() and "LEGI" in subdir.name:
                legi_dir = subdir
                break
    
    if not legi_dir.exists():
        logger.error(f"‚ùå Dossier LEGI non trouv√© dans {extract_dir}")
        return 0
    
    logger.info(f"üìÇ Dossier LEGI: {legi_dir}")
    
    # Trouver les codes
    code_dirs = [d for d in legi_dir.iterdir() if d.is_dir() and d.name.startswith("LEGITEXT")]
    
    if not code_dirs:
        logger.warning("‚ö†Ô∏è Aucun code trouv√©")
        return 0
    
    logger.info(f"üìö {len(code_dirs)} codes trouv√©s")
    
    # Filtrer si code_ids sp√©cifi√©s
    if code_ids:
        code_dirs = [d for d in code_dirs if d.name in code_ids]
        logger.info(f"üìö {len(code_dirs)} codes √† ing√©rer")
    
    total_articles = 0
    
    for code_dir in code_dirs:
        code_id = code_dir.name
        code_name = CODE_MAPPING.get(code_id, code_id)
        
        logger.info(f"\nüìñ Code: {code_name} ({code_id})")
        
        # Trouver les fichiers XML
        xml_files = client.find_xml_files(code_dir)
        
        if not xml_files:
            logger.warning(f"   ‚ö†Ô∏è Aucun fichier XML trouv√©")
            continue
        
        logger.info(f"   üìÑ {len(xml_files)} fichiers XML")
        
        # Parser les fichiers
        articles = []
        for xml_file in xml_files:
            parsed = client.parse_legi_xml(xml_file)
            articles.extend(parsed)
        
        logger.success(f"   ‚úÖ {len(articles)} articles pars√©s")
        total_articles += len(articles)
    
    logger.success(f"\n‚úÖ Total: {total_articles} articles ing√©r√©s")
    return total_articles


def main():
    """Fonction principale"""
    # 1. T√©l√©charger
    archive_path = download_freemium()
    if not archive_path:
        logger.error("‚ùå √âchec t√©l√©chargement")
        return
    
    # 2. Extraire
    extract_dir = extract_archive(archive_path)
    if not extract_dir:
        logger.error("‚ùå √âchec extraction")
        return
    
    # 3. Ing√©rer
    total = ingest_from_extracted(extract_dir)
    
    logger.info("=" * 70)
    logger.success(f"‚úÖ PROCESSUS TERMIN√â: {total} articles ing√©r√©s")
    logger.info("=" * 70)


if __name__ == "__main__":
    main()

