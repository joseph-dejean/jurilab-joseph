#!/bin/bash
# Script pour importer tous les fichiers JSONL dans Vertex AI Search
# √Ä ex√©cuter dans Google Cloud SDK Shell

PROJECT_ID="jurilab-481600"
DATASTORE_ID="datastorerag_1766055384992"
LOCATION="global"
BUCKET="gs://legal-rag-data-sofia-2025"

echo "============================================================"
echo "üöÄ IMPORT VERS VERTEX AI SEARCH"
echo "============================================================"
echo "üìÇ Datastore: $DATASTORE_ID"
echo "üì¶ Bucket: $BUCKET"
echo ""

# Lister tous les fichiers JSONL
echo "üìã Liste des fichiers √† importer:"
gsutil ls ${BUCKET}/*.jsonl | while read file; do
    echo "  - $(basename $file)"
done

echo ""
echo "üì§ D√©but de l'import..."
echo ""

# Compter les fichiers
TOTAL=$(gsutil ls ${BUCKET}/*.jsonl | wc -l)
COUNT=0

# Importer chaque fichier
gsutil ls ${BUCKET}/*.jsonl | while read file; do
    COUNT=$((COUNT + 1))
    FILENAME=$(basename $file)
    
    echo "[$COUNT/$TOTAL] Import: $FILENAME"
    
    gcloud alpha discovery-engine documents import \
        --datastore=$DATASTORE_ID \
        --location=$LOCATION \
        --gcs-uri=$file \
        --project=$PROJECT_ID
    
    if [ $? -eq 0 ]; then
        echo "  ‚úÖ Succ√®s"
    else
        echo "  ‚ùå Erreur"
    fi
    
    echo ""
done

echo "============================================================"
echo "‚úÖ Import termin√©"
echo "============================================================"

