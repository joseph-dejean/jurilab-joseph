# üì§ Guide : Importer tous les fichiers dans Vertex AI Search

## Probl√®me

Vertex AI Search ne supporte **pas les wildcards** (`*.jsonl`) dans les chemins GCS. Il faut importer chaque fichier individuellement.

## Solution : Script d'import automatique

### Option 1 : Script batch (Windows - Google Cloud SDK Shell)

1. **Ouvrir Google Cloud SDK Shell**
2. **Naviguer vers le projet** :
   ```bash
   cd "C:\Users\sofia\Desktop\perso\rag juridique"
   ```
3. **Ex√©cuter le script** :
   ```bash
   import_all_to_vertex.bat
   ```

Le script va :
- Lister tous les fichiers JSONL dans GCS
- Importer chaque fichier un par un
- Afficher la progression

**Dur√©e estim√©e** : ~2-4 heures pour 87 fichiers

### Option 2 : Via Console GCP (manuel)

1. Aller sur [Google Cloud Console](https://console.cloud.google.com)
2. Vertex AI ‚Üí Search ‚Üí Data Stores ‚Üí `datastorerag_1766055384992` ‚Üí Import
3. Pour **chaque fichier** (87 fois) :
   - Source : Cloud Storage
   - Path : `gs://legal-rag-data-sofia-2025/NOM_DU_FICHIER.jsonl`
   - Format : JSONL
   - Import

‚ö†Ô∏è **Long et fastidieux** avec 87 fichiers

### Option 3 : Script Python (alternative)

Si vous pr√©f√©rez Python :

```python
from pathlib import Path
from config.settings import get_settings

settings = get_settings()
jsonl_files = list(settings.EXPORT_DIR.glob("*.jsonl"))

for f in jsonl_files:
    gcs_path = f"gs://legal-rag-data-sofia-2025/{f.name}"
    print(f"gcloud alpha discovery-engine documents import \\")
    print(f"  --datastore=datastorerag_1766055384992 \\")
    print(f"  --location=global \\")
    print(f"  --gcs-uri={gcs_path}")
```

Puis copier-coller les commandes dans Google Cloud SDK Shell.

## ‚è±Ô∏è Dur√©e estim√©e

- **Import** : ~2-4 heures pour 87 fichiers
- **Indexation** : ~2-4 heures suppl√©mentaires pour 488,635 articles
- **Total** : ~4-8 heures

## ‚úÖ V√©rification

Apr√®s l'import, v√©rifier dans la console :
- Statut : `Completed`
- Documents import√©s : ~488,635
- Puis tester : `python test_search.py`

