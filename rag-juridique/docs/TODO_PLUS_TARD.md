# üìã √Ä faire plus tard (Backlog)

**Fichier de suivi des fonctionnalit√©s et probl√®mes √† r√©soudre ult√©rieurement**

---

## üî¥ Priorit√© HAUTE

### 1. ‚úÖ Configuration Gemini API (Pilier 5 - Chatbot) - R√âSOLU

**Statut : R√âSOLU LE 18 D√âCEMBRE 2025** ‚úÖ

**Probl√®me initial :**
L'API Gemini renvoyait une erreur 403 "ACCESS_TOKEN_SCOPE_INSUFFICIENT" lors de la g√©n√©ration de contenu via Vertex AI Gemini.

**Solution impl√©ment√©e :**
Utilisation de l'**API Gemini directe** avec cl√© API (obtenue via Google AI Studio) au lieu de Vertex AI Gemini.

**Configuration actuelle :**
- Mod√®les utilis√©s : `models/gemini-flash-latest` (rapide) et `models/gemini-pro-latest` (puissant)
- Authentification : `GEMINI_API_KEY` dans `.env`
- RAG : Vertex AI Search (inchang√©)
- G√©n√©ration : API Gemini directe

**R√©sultats :**
- ‚úÖ G√©n√©ration de r√©ponses juridiques de qualit√© (confiance 95%)
- ‚úÖ Citations pr√©cises des sources du Code Civil
- ‚úÖ Historique de conversation fonctionnel
- ‚úÖ Suggestions intelligentes

**Note importante :** L'API Gemini directe utilise EXACTEMENT le m√™me RAG (Vertex AI Search).
- **Gemini fait UNIQUEMENT :** La mise en texte √©l√©gante des sources r√©cup√©r√©es par le RAG
- **Gemini ne fait PAS :** La recherche (c'est Vertex AI Search qui s'en charge)

**Migration future possible (Phase 4 - Optionnel) :**

Si n√©cessaire, migration vers **Vertex AI Gemini** pour unifier l'√©cosyst√®me :

**Avantages potentiels :**
- Facturation unifi√©e GCP
- Quotas partag√©s avec Vertex AI Search
- Pas de gestion de cl√© API s√©par√©e

**Pr√©requis :**
- Activer facturation GCP compl√®te
- V√©rifier disponibilit√© Vertex AI Gemini dans la r√©gion
- Tester acc√®s aux mod√®les via Vertex AI

**Note :** Le package `google.generativeai` est d√©pr√©ci√©. Migration vers `google.genai` recommand√©e √† long terme.

**Timeline :** Phase 4 (optionnel - solution actuelle pleinement fonctionnelle)

---

### 2. Filtres Vertex AI Search (Pilier 2 - Super-Chercheur)

**Probl√®me :**
Les filtres sur les champs nested (`metadata.*`) ne fonctionnent pas avec Vertex AI Search dans la configuration actuelle.

**Erreur :**
```
Invalid filter syntax 'metadata.etat="VIGUEUR"'. 
Parsing filter failed with error: Unsupported field "metadata.etat" 
on comparison operators.
```

**Filtres concern√©s :**
- `metadata.etat` (VIGUEUR, ABROGE, MODIFIE)
- `metadata.code_id` (ID du code juridique)
- `metadata.jurisdiction` (Juridiction)
- `metadata.matter` (Mati√®re juridique)
- `metadata.date_debut` / `metadata.date_fin` (Dates)
- `metadata.article_num` (Num√©ro d'article)

**Impact actuel :**
- La recherche fonctionne parfaitement en mode s√©mantique pur
- Impossibilit√© de filtrer par crit√®res sp√©cifiques
- Tous les r√©sultats sont retourn√©s sans filtrage

**Solutions possibles (√† investiguer) :**

#### Option A : Syntaxe Vertex AI correcte
Investiguer la documentation Vertex AI pour trouver la syntaxe exacte pour filtrer les champs nested.

**Pistes :**
- Peut-√™tre utiliser `jsonData.metadata.etat` au lieu de `metadata.etat`
- Peut-√™tre une syntaxe sp√©ciale pour les champs JSON
- Consulter les exemples officiels Google

**Documentation √† consulter :**
- https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata
- https://cloud.google.com/generative-ai-app-builder/docs/schema

#### Option B : Restructuration du JSONL
D√©placer les champs de m√©tadonn√©es au niveau racine du document.

**Format actuel :**
```json
{
  "id": "LEGIARTI...",
  "jsonData": "{\"content\": \"...\", \"title\": \"...\", \"metadata\": {\"etat\": \"VIGUEUR\", ...}}"
}
```

**Format propos√© :**
```json
{
  "id": "LEGIARTI...",
  "etat": "VIGUEUR",
  "code_id": "LEGITEXT...",
  "article_num": "1101",
  "jsonData": "{\"content\": \"...\", \"title\": \"...\"}"
}
```

**Avantages :**
- Filtres directement accessibles (`etat="VIGUEUR"`)
- Pas besoin de prefix `metadata.`

**Inconv√©nients :**
- N√©cessite r√©-ingestion compl√®te des donn√©es
- Modification des scripts d'ingestion
- Possible duplication de donn√©es

#### Option C : Post-filtrage c√¥t√© application
Impl√©menter le filtrage c√¥t√© Python apr√®s r√©cup√©ration des r√©sultats.

**Impl√©mentation :**
```python
def _apply_client_side_filters(
    results: list[SearchResult],
    filters: SearchFilters
) -> list[SearchResult]:
    """Filtre les r√©sultats c√¥t√© application"""
    filtered = results
    
    if filters.etat:
        filtered = [r for r in filtered if r.metadata.get("etat") == filters.etat.value]
    
    if filters.code_id:
        filtered = [r for r in filtered if r.metadata.get("code_id") == filters.code_id]
    
    # ... autres filtres
    
    return filtered
```

**Avantages :**
- Impl√©mentation rapide
- Pas de modifications des donn√©es
- Fonctionne imm√©diatement

**Inconv√©nients :**
- Performance d√©grad√©e (r√©cup√®re trop de r√©sultats)
- Gaspillage de bande passante
- Pagination complexe

#### Option D : Combinaison des approches
1. Impl√©menter post-filtrage (Option C) en **Phase 2** pour d√©bloquer la fonctionnalit√©
2. Investiguer la syntaxe Vertex AI (Option A) en parall√®le
3. Si n√©cessaire, restructurer le JSONL (Option B) en **Phase 3**

**Recommandation : Option D** ‚úÖ

---

**Timeline :**
- **Phase 2 (Semaine prochaine) :** Impl√©menter Option C (post-filtrage)
- **Phase 2 (Parall√®le) :** Investiguer Option A (syntaxe Vertex AI)
- **Phase 3 (Si n√©cessaire) :** Option B (restructuration)

**Fichiers √† modifier :**
- `api/super_chercheur.py` ‚Üí m√©thode `_build_vertex_filters()` ou nouvelle m√©thode `_apply_client_side_filters()`
- `ingestion/ingestion_codes.py` ‚Üí si restructuration JSONL (Option B)
- `ingestion/create_test_dataset.py` ‚Üí si restructuration JSONL (Option B)

**Tests √† ajouter :**
- Tests unitaires des filtres
- Tests d'int√©gration avec diff√©rents crit√®res
- Tests de performance (avec/sans filtres)

---

## üü° Priorit√© MOYENNE

### 2. Am√©lioration du calcul de probabilit√© de succ√®s

**Situation actuelle :**
Estimation basique bas√©e sur la moyenne des scores de pertinence.

**Am√©liorations pr√©vues :**
- Mod√®le ML entra√Æn√© sur historique de d√©cisions
- Analyse des issues (favorable/d√©favorable)
- Prise en compte du contexte proc√©dural
- Facteurs temporels (√©volution jurisprudence)

**Timeline :** Phase 3

---

### 3. Extraction d'arguments juridiques avanc√©e

**Situation actuelle :**
Extraction simple de mots-cl√©s depuis les breadcrumbs.

**Am√©liorations pr√©vues :**
- NER (Named Entity Recognition) juridique
- Extraction bas√©e sur LLM (Gemini)
- Analyse s√©mantique des motifs de d√©cision
- Identification d'arguments r√©currents

**Outils potentiels :**
- Theolex (legal-doc-processing)
- Spacy + mod√®le juridique fran√ßais
- Gemini avec prompt engineering

**Timeline :** Phase 3

---

### 4. Cache des r√©sultats de recherche

**Objectif :**
Acc√©l√©rer les requ√™tes fr√©quentes et r√©duire les co√ªts API.

**Impl√©mentation sugg√©r√©e :**
```python
# Utiliser Redis ou memcache
import redis

cache = redis.Redis(host='localhost', port=6379, db=0)

def cached_search(query: str, filters: dict) -> SearchResponse:
    cache_key = f"search:{hash(query)}:{hash(str(filters))}"
    
    # V√©rifier cache
    cached = cache.get(cache_key)
    if cached:
        return SearchResponse.parse_raw(cached)
    
    # Requ√™te r√©elle
    response = vertex_client.search(...)
    
    # Mettre en cache (TTL: 1h)
    cache.setex(cache_key, 3600, response.json())
    
    return response
```

**Timeline :** Phase 4

---

### 5. API PISTE L√©gifrance - R√©solution erreur 500

**Probl√®me :**
L'API PISTE renvoie syst√©matiquement une erreur 500 (Internal Server Error).

**Status :**
- ‚úÖ Message envoy√© au support PISTE (17 d√©c 2025)
- ‚è≥ En attente de r√©ponse

**Workaround actuel :**
Utilisation de data.gouv.fr pour l'ingestion.

**√Ä faire quand r√©solu :**
1. Tester la connexion API
2. Lancer l'ingestion compl√®te du Code Civil (8,000 articles)
3. Ing√©rer les autres codes (P√©nal, Travail, Commerce, Proc√©dure Civile)
4. Comparer qualit√© des donn√©es PISTE vs data.gouv.fr

**Timeline :** D√®s que support PISTE r√©pond

---

## üü¢ Priorit√© BASSE

### 6. Internationalisation du Pilier 3 (Audit)

**Probl√®me :**
Le syst√®me actuel ne fonctionne QUE pour le droit fran√ßais avec des patterns sp√©cifiques.

**Limites actuelles :**
```python
# ‚úÖ Fonctionne :
"article 1101 du Code civil" (France)

# ‚ùå Ne fonctionne PAS :
"18 U.S.C. ¬ß 1001" (USA)
"Section 1 of the Contract Act" (UK)
"¬ß 242 BGB" (Allemagne)
"Art√≠culo 1261 del C√≥digo Civil" (Espagne)
```

**Challenges pour l'international :**
1. **Patterns diff√©rents** : Chaque pays a ses conventions
2. **Langues diff√©rentes** : FR, EN, DE, ES, IT, etc.
3. **Syst√®mes juridiques** : Common Law vs Civil Law vs autres
4. **Codes diff√©rents** : Nomenclatures nationales
5. **Bases de donn√©es** : L√©gifrance vs Westlaw vs BeckOnline vs EUR-Lex

**Variations d'√©criture m√™me en France :**
- "art. 1101" (abr√©viation)
- "article premier" (ordinal en lettres)
- "article 1101, al. 2" (avec alin√©a)
- "articles 1101 √† 1105" (plages)
- "article 1101-1" (sous-num√©rotation)

**Solutions possibles :**

#### Option A : Regex multilingue (simple mais rigide)
D√©finir des patterns pour chaque pays.

**Avantages :**
- Rapide √† impl√©menter
- D√©terministe

**Inconv√©nients :**
- Maintenance cauchemardesque
- Rigide
- Rate les variantes

#### Option B : NLP multilingue (flexible)
Utiliser Spacy avec mod√®les par langue et entit√©s personnalis√©es.

**Avantages :**
- Flexible
- Extensible
- G√®re les variantes

**Inconv√©nients :**
- Complexe
- N√©cessite training
- Co√ªteux en ressources

#### Option C : API de normalisation (id√©al)
Service externe qui normalise les r√©f√©rences juridiques.

**Architecture :**
```python
class LegalAuditor:
    def __init__(self, country: str):
        self.extractor = ReferenceExtractorFactory.create(country)
        self.verifier = ReferenceVerifierFactory.create(country)
        self.database = LegalDatabaseFactory.create(country)
```

**Roadmap recommand√©e :**
1. **Phase 1 (MVP)** : France uniquement
   - Am√©liorer regex pour "art.", "al.", "premier"
   - Dataset complet
   
2. **Phase 2** : France + Belgique/Suisse
   - M√™me langue, patterns similaires
   - Codes similaires (Code civil belge/suisse)
   
3. **Phase 3** : + USA/UK
   - Common Law (patterns tr√®s diff√©rents)
   - Nouvelles bases (Westlaw, LexisNexis)
   
4. **Phase 4** : + UE + Allemagne/Espagne/Italie
   - EUR-Lex pour droit europ√©en
   - Autres langues

**Fichiers √† cr√©er :**
- `api/extractors/` ‚Üí Extracteurs par pays
- `api/verifiers/` ‚Üí V√©rificateurs par syst√®me juridique
- `api/databases/` ‚Üí Adaptateurs pour bases de donn√©es
- `config/legal_systems.yaml` ‚Üí Configuration par pays

**Timeline :** Phase 4-5 (apr√®s MVP France complet)

**Priorit√© :** BASSE (MVP France suffit pour d√©monstration)

---

### 7. Pagination des r√©sultats

**Situation actuelle :**
Tous les r√©sultats sont retourn√©s en une seule fois (max 100).

**Am√©lioration pr√©vue :**
```python
class SearchRequest(BaseModel):
    page: int = 1
    page_size: int = 10

class SearchResponse(BaseModel):
    results: list[SearchResult]
    total: int
    page: int
    total_pages: int
    has_next: bool
    has_previous: bool
```

**Timeline :** Phase 4

---

### 7. Export des r√©sultats

**Formats souhait√©s :**
- PDF (rapport de recherche)
- DOCX (document √©ditable)
- CSV (tableau de r√©sultats)
- JSON (pour int√©gration)

**Timeline :** Phase 4

---

### 8. Recherche par similarit√© de cas

**Concept :**
"Trouver des cas similaires √† cette d√©cision" (upload PDF/DOCX).

**Impl√©mentation :**
1. Extraire le texte du document
2. G√©n√©rer un embedding
3. Rechercher par similarit√© vectorielle dans Vertex AI

**Timeline :** Phase 4

---

### 9. Suggestions de requ√™tes

**Concept :**
Sugg√©rer des reformulations ou des requ√™tes connexes.

**Exemple :**
```
Recherche: "contrat"
Suggestions:
  ‚Ä¢ "formation du contrat"
  ‚Ä¢ "nullit√© du contrat"
  ‚Ä¢ "r√©siliation du contrat"
```

**Timeline :** Phase 4

---

### 10. Historique de recherche

**Fonctionnalit√©s :**
- Sauvegarder les recherches par utilisateur
- Suggestions bas√©es sur l'historique
- Statistiques d'utilisation

**Timeline :** Phase 4

---

## üîµ Optimisations techniques

### 11. Tests unitaires complets

**√Ä ajouter :**
```
tests/
‚îú‚îÄ‚îÄ test_super_chercheur.py
‚îú‚îÄ‚îÄ test_vertex_search.py
‚îú‚îÄ‚îÄ test_models.py
‚îî‚îÄ‚îÄ test_ingestion.py
```

**Timeline :** Phase 2

---

### 12. CI/CD Pipeline

**Outils :**
- GitHub Actions
- Tests automatiques
- Linting (ruff, mypy)
- D√©ploiement automatique

**Timeline :** Phase 4

---

### 13. Monitoring & Observabilit√©

**Outils :**
- Sentry (error tracking)
- Prometheus + Grafana (m√©triques)
- Cloud Logging (logs centralis√©s)

**Timeline :** Phase 4

---

## üìù Notes

### Comment utiliser ce fichier

1. **Ajouter un nouveau TODO :**
   - Choisir la priorit√© (HAUTE, MOYENNE, BASSE)
   - D√©crire le probl√®me/fonctionnalit√©
   - Proposer des solutions
   - Estimer la timeline

2. **D√©placer vers la TODO list active :**
   Quand on commence une t√¢che, la d√©placer vers la TODO list principale et mettre √† jour le statut.

3. **Archiver :**
   Quand une t√¢che est termin√©e, la supprimer de ce fichier et la documenter dans le CHANGELOG.

---

**Derni√®re mise √† jour :** 18 D√©cembre 2025  
**Prochaine r√©vision :** Fin de Phase 1 (apr√®s d√©veloppement des 5 piliers)

